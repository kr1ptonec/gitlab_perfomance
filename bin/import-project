#!/usr/bin/env ruby

$LOAD_PATH.unshift File.expand_path('../lib', __dir__)

require 'chronic_duration'
require 'down/http'
require 'gpt_common'
require 'optimist'
require 'time'
require 'uri'

opts = Optimist.options do
  banner "Usage: import-project [options]"
  banner "\nImports a GitLab Project tarball (local or remote) into the specified environment.\nDefaults to importing the gitlabhq project from a remote filestore to the specified environment, group and project namespace."
  banner "\nOptions:"
  opt :environment_url, "Full URL for the environment to import to.", short: :none, type: :string, required: true
  opt :project_tarball, "Location of project tarball to import. Can be local or remote.", short: :none, type: :string, default: 'https://gitlab.com/gitlab-org/quality/performance-data/raw/master/gitlabhq_export.tar.gz'
  opt :namespace, "The ID or path of the namespace that the project will be imported to, such as a Group.", short: :none, type: :string
  opt :project_name, "Name for project. Can be also be a combined path and name if required.", short: :none, type: :string, required: true
  opt :storage_name, "Name for target repository storage (Gitaly).", short: :none, type: :string, default: 'default'
  opt :help, 'Show help message'
  banner "\nEnvironment Variables:"
  banner "  ACCESS_TOKEN             A valid GitLab Personal Access Token for the specified environment. The token should have admin access for the ability to import projects. (Default: nil)"
  banner "\nExamples:"
  banner "  import-project --environment-url 10k.testbed.gitlab.net"
  banner "  import-project --environment-url localhost:3000 --project-tarball /home/user/test-project.tar.gz --namespace test-group --project-name test-project"
end

raise 'Environment Variable ACCESS_TOKEN must be set to proceed. See command help for more info' unless ENV['ACCESS_TOKEN']

headers = {
  'Authorization': "Bearer #{ENV['ACCESS_TOKEN']}"
}

puts "Starting import of Project '#{opts[:project_name]}' from tarball '#{opts[:project_tarball]}'" + (opts[:namespace] ? " under namespace '#{opts[:namespace]}'" : '') + " to GitLab environment '#{opts[:environment_url]}'\n\n"

# Check that environment can be reached and that token is valid
puts "Checking that GitLab environment '#{opts[:environment_url]}' is available and that provided Access Token works..."
check_res = GPTCommon.make_http_request(method: 'get', url: URI.join(opts[:environment_url], '/api/v4/version').to_s, headers: headers)
raise "Environment check has failed:\n#{check_res.status} - #{JSON.parse(check_res.body.to_s)}" if check_res.status.client_error? || check_res.status.server_error?

version = JSON.parse(check_res.body.to_s).values.join(' ')
puts "Environment and Access Token check was successful - URL: #{opts[:environment_url]}, Version: #{version}\n\n"

# Check that the tarball file is valid
if opts[:project_tarball].match?(URI.regexp(%w[http https ftp]))
  puts "Tarball is remote, downloading..."
  proj_file = Down::Http.download(opts[:project_tarball])
else
  proj_file = opts[:project_tarball]
end
raise Errno::ENOENT unless File.exist?(proj_file)

# Create Group
if opts[:namespace] && !GPTCommon.make_http_request(method: 'get', url: URI.join(opts[:environment_url], "/api/v4/namespaces/#{opts[:namespace]}").to_s, headers: headers, fail_on_error: false).status.success?
  puts "Creating Namespace #{opts[:namespace]}..."
  grp_url = URI.join(opts[:environment_url], '/api/v4/groups').to_s
  grp_params = {
    name: opts[:namespace],
    path: opts[:namespace],
    visibility: 'public'
  }
  GPTCommon.make_http_request(method: 'post', url: grp_url, params: grp_params, headers: headers)
end

# Create Project
puts "Importing project #{opts[:project_name]}..."
start_time = Time.now.to_i
proj_url = URI.join(opts[:environment_url], '/api/v4/projects/import').to_s
proj_params = {
  file: HTTP::FormData::File.new(proj_file),
  namespace: opts[:namespace],
  path: opts[:project_name],
  'override_params[repository_storage]': opts[:storage_name]
}
# we need to enable chunked transfers so cloudfare won't reject uploads > 100MB
upload_headers = {
  'Transfer-Encoding': 'chunked'
}.merge(headers)
proj_res = GPTCommon.make_http_request(method: 'post', url: proj_url, params: proj_params, headers: upload_headers, show_response: true)
proj_id = JSON.parse(proj_res.body.to_s)['id']

puts "\nProject tarball has successfully uploaded and started to be imported with ID '#{proj_id}'"
print "Waiting until Project '#{proj_id}' has imported successfully..."
loop do
  proj_imp_res = JSON.parse(GPTCommon.make_http_request(method: 'get', url: URI.join(opts[:environment_url], "/api/v4/projects/#{proj_id}/import").to_s, headers: headers).body.to_s)

  case proj_imp_res['import_status']
  when 'finished'
    time_taken = ChronicDuration.output(Time.now.to_i - start_time, format: :long)
    puts "\nProject has successfully imported in #{time_taken}:\n#{URI.join(opts[:environment_url], proj_imp_res['path_with_namespace'])}"
    exit
  when 'failed'
    raise "Project has failed to import. Reason:\n#{proj_imp_res['import_error']}"
  when 'scheduled', 'started'
    print '.'
    sleep 5
  else
    sleep 5
  end
end
