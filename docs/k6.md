# GitLab Performance Tool - Running the Tests

* [GitLab Performance Tool - Preparing the Environment](environment_prep.md)
* [**GitLab Performance Tool - Running the Tests**](k6.md)

On this page we'll detail how to configure and run [k6](https://k6.io/) tests against a GitLab environment with the GitLab Performance Tool (gpt). Note that we assume you have a working knowledge of [k6](https://k6.io/) and [Docker](https://www.docker.com/).

**Note: Before running any tests with the Tool, the intended GitLab environment should be prepared first. Details on how to do this can be found here: [GitLab Performance Tool - Preparing the Environment](environment_prep.md)**

* [Tool Requirements](#tool-requirements)
* [Configuring the Tool](#configuring-the-tool)
  * [Environments](#environments)
  * [Options](#options)
  * [Tests](#tests)
* [Running the Tests with the Tool](#running-the-tests-with-the-tool)
  * [Docker (Recommended)](#docker-recommended)
  * [Linux](#linux)
  * [Test Output and Results](#test-output-and-results)
    * [Evaluating Failures](#evaluating-failures)
    * [Comparing Results](#comparing-results)
* [Troubleshooting](#troubleshooting)
  * [`socket: too many open files`](#socket-too-many-open-files)

## Tool Requirements

The minimum hardware and software requirements for running the Tool are dependent on the intended load target (given as Requests per Second or RPS), the underlying hardware and the complexity of the tests being run.

As a rule of thumb, we recommend that to run the default tests at **200 RPS** the machine running the Tool has approximately **1 CPU Core** and **1 GB RAM** available.

So for example, to run the default tests at the following RPS targets the machine should have these specs available as a minimum:
* 200 RPS - 1 Core CPU, 1 GB RAM
* 500 RPS - 2 Core CPU, 2.5 GB RAM
* 1000 RPS - 4 Core CPU, 5 GB RAM

We recommend running the tool with [Docker](https://www.docker.com/) but the tool can also be run on Linux natively. More details can be found in the [Running the Tests with the Tool](#running-the-tests-with-the-tool) section below.

## Configuring the Tool

Before you can run performance tests with the tool against your GitLab environment you need to configure it. This involves configuring the tool with all of the required info about your environment, the project(s) you intend to test against, any additional tests you wish to run and optionally to run the tests.

There are three key pieces of configuration in the tool - [Environments](../k6/environments), [Options](../k6/options) and [Tests](../k6/tests). This section details each as follows.

Out of the box all the default k6 tests are configured to run against an environment that has at least one instance of the default Test Project setup (see [GitLab Performance Tool - Preparing the Environment](environment_prep.md) for more info). However, this is configurable and the tool can be configured to run against any project providing it has equivalent data to test (more details in the next section).

### Environments

The first piece of configuration is the [Environment Config File](../k6/environments). This file should contain the environment's information, such as it's URL, as well as the required details for each project the tests will run against.

As an example, the following is one of our Environment Config Files, [`10k.json`](../k6/environments/10k.json), that configures the tests on where to find the Environment and what Projects to test against:

```json
{
  "environment": {
    "name": "10k",
    "url": "http://10k.testbed.gitlab.net"
  },
  "projects": [
    {
      "name": "gitlabhq",
      "group": "qa-perf-testing",
      "commit_sha": "0a99e022",
      "commit_sha_signed": "6526e91f",
      "branch": "10-0-stable",
      "file_path": "qa%2fqa%2erb",
      "mr_commits_iid": "10495",
      "mr_discussions_iid": "6958",
      "user": "root"
    },
    {
      "name": "gitlabhq2",
      "group": "qa-perf-testing",
      "commit_sha": "0a99e022",
      "commit_sha_signed": "6526e91f",
      "branch": "10-0-stable",
      "file_path": "qa%2fqa%2erb",
      "mr_commits_iid": "10495",
      "mr_discussions_iid": "6958",
      "user": "root"
    }
  ]
}
```

* The environment's Name and URL.
    * Note as a convenience these two settings can also be defined as environment variables, `ENVIRONMENT_NAME` and `ENVIRONMENT_URL` respectively, for overriding as required.
* Details for each project that the tests should target. You should aim to have each of these details present here and in the target environment otherwise the specific tests that require them will be skipped automatically:
    * `name` - Name of the Project.
    * `group` - The name of the Group that contains the intended Project.
    * `commit_sha` - The SHA reference of a large commit available in the project. The size of the commit should be tuned to your environment's requirements.
    * `commit_sha_signed` - The SHA reference of a [signed commit](https://docs.gitlab.com/ee/user/project/repository/gpg_signed_commits/) available in the project.
    * `branch` - The name of a large branch available in the project. The size of the branch should be tuned to your environment's requirements.
    * `file_path` - The relative path to a normal sized file in your project.
    * `mr_commits_iid` - The [iid](https://docs.gitlab.com/ee/api/#id-vs-iid) of a merge request available in the project that has a large number of commits. The size of the MR should be tuned to your environment's requirements.
    * `mr_discussions_iid` - The [iid](https://docs.gitlab.com/ee/api/#id-vs-iid) of a merge request available in the project that has a large number of discussions / comments. The size of the MR discussions should be tuned to your environment's requirements.
    * `user` - The name of a valid user for testing related endpoints.

### Options

The second piece of configuration is the [Options Config File](../k6/options). This file will set how the tool will run the tests - e.g. how long to run the tests for, how many users and how much throughput.

The [Options Config Files](../k6/options) are themselves native [k6 config files](https://docs.k6.io/docs/options). For this tool, we use them to set options but they can also be used to set any valid k6 options as required for advanced use cases.

As an example, the following is one of our Options Config Files, [`20s_2rps.json`](../k6/options/20s_2rps.json), that configures the tests to each run for 20 seconds at a rate of 2 Requests Per Second (RPS):

```json
{
  "stages": [
    { "duration": "5s", "target": 20 },
    { "duration": "10s", "target": 20 },
    { "duration": "5s", "target": 0 }
  ],
  "rps": 20,
  "batchPerHost": 0,
  "maxRedirects": 0
}
```

* `stages` - Defines the stages k6 should run the tests with. Sets the duration of each stage and how many users (VUs) to use. 
    * It should be noted that each stage will ramp up from the previous, so in this example the scenario is to ramp up from 0 to 2 users over 5 seconds and then maintain 2 users for another 15s.
* `rps` - Sets the maximum Requests per Second that k6 can make in total.
* `batchPerHost` - Sets k6 to allow unlimited requests to the same host in [batch](https://docs.k6.io/docs/batch-requests) calls.
* `maxRedirects` - Sets the max number of redirects k6 will follow to none.

Note that it's best practice to set the number of users (VUs) to the same amount as RPS to ensure the target RPS can be reached.

### Tests

Finally we have the third and last piece of configuration - the [k6 test scripts](https://docs.k6.io/docs/running-k6#section-executing-local-scripts). Each file contains a test to run against the environment along with any extra config such as setting thresholds.

To get more detailed information about the current test list you can refer to the [Current Test Details wiki page](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details).

Like Options, test files are native [k6 test scripts](https://docs.k6.io/docs/running-k6#section-executing-local-scripts) and all valid k6 features and options can be used here.

With the tool, we provide various curated tests and libraries that are designed to performance test a wide range of GitLab functions. We continue to iterate and release tests also. In each test we set the actions to take (e.g. call an API) along with defining thresholds that determine if the test is a success (e.g. actual RPS should be no less than 20% of the target and no more than 5% of requests made can be failures).

As an example, the following is one of our API Tests, [`api_v4_projects_project.js`](../k6/tests/api/api_v4_projects_project.js), that tests the [GET Single Project API](https://docs.gitlab.com/ee/api/projects.html#get-single-project):

```js
/*global __ENV : true  */
/*
@endpoint: `GET /projects/:id`
@description: [Get single project](https://docs.gitlab.com/ee/api/projects.html#get-single-project)
*/

import http from "k6/http";
import { group, fail } from "k6";
import { Rate } from "k6/metrics";
import { logError, getRpsThresholds, getProjects, selectProject } from "../../lib/gpt_k6_modules.js";

if (!__ENV.ACCESS_TOKEN) fail('ACCESS_TOKEN has not been set. Skipping...')

export let rpsThresholds = getRpsThresholds()
export let successRate = new Rate("successful_requests");
export let options = {
  thresholds: {
    "successful_requests": [`rate>${__ENV.SUCCESS_RATE_THRESHOLD}`],
    "http_reqs": [`count>=${rpsThresholds['count']}`]
  }
};

export let projects = getProjects(['name', 'group']);

export function setup() {
  console.log('')
  console.log(`RPS Threshold: ${rpsThresholds['mean']}/s (${rpsThresholds['count']})`)
  console.log(`Success Rate Threshold: ${parseFloat(__ENV.SUCCESS_RATE_THRESHOLD)*100}%`)
}

export default function() {
  group("API - Project Overview", function() {
    let project = selectProject(projects);

    let params = { headers: { "Accept": "application/json", "PRIVATE-TOKEN": `${__ENV.ACCESS_TOKEN}` } };
    let res = http.get(`${__ENV.ENVIRONMENT_URL}/api/v4/projects/${project['group']}%2F${project['name']}`, params);
    /20(0|1)/.test(res.status) ? successRate.add(true) : successRate.add(false) && logError(res);
  });
}
```

The above script is to test the Projects API, namely to [get the details of a specific project](https://docs.gitlab.com/ee/api/projects.html#get-single-project).

The script does the following:
* Informs `eslint` that global environment variables are to be used.
* Sets some tags describing the test that are used by the tool for filtering tests as well as by GitLab Quality for [reporting](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details).
* Imports the various k6 libraries and our own custom modules that we use in the script
* Fails the test if the `ACCESS_TOKEN` environment variable hasn't be set on the machine as this test requires it to authenticate. (more details on the token can be found in the [Running Tests](#running-tests) section)
* Configures the Thresholds that will be used to determine if the test has passed or not (more details on the thresholds can be found in the [Test Results](#test-results) section).
* Loads in the Projects defined in the Environment config file that have the `name` and `group` variables defined. If none found the test is skipped and if multiple is found the test will perform runs against each.
* Logs some useful info in the k6 pre function `setup()` that the tool will use for reporting.
* Finally the main test script itself is last. It selects a Project at random, sets the required headers and then calls the endpoint on the Environment. It then checks if the response was valid, adds the result to the threshold and calls our custom module to report any errors once in the test output.

Note that the above is an example of a typical test. Other [tests](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details) may vary in their approach depending on the area being targeted.

### Test Types

The Tool provides several different types of performance tests that aim to cover the GitLab application. Depending on the type of test you'll see the tool adjust the RPS target accordingly (via adjusting the main RPS target by percentage) as each have a different target throughput based on user patterns.

There are three main types of tests that the Tool provides:
* [`API`](../k6/tests/api) - Tests that target [API](https://docs.gitlab.com/ee/api/) endpoints (RPS target: 100%)
* [`Git`](../k6/tests/git) - Tests that target Git endpoints (RPS target: 10%)
* [`Web`](../k6/tests/web) - Tests that target Web page endpoints (RPS target: 10%)
  * Note that the underlying software this tool is based on, k6, [only tests the response time of the Web page source and doesn't render the page itself](https://docs.k6.io/docs/welcome#section-k6-does-not). This means it won't performance test any HTTP calls found in dynamic scripts, etc... More accurate web page tests could be emulated via [k6's HAR conversion tool](https://docs.k6.io/docs/session-recording-har-support_) but again note this would only measure response time and not rendering time. To measure Rendering time of pages we recommend [sitespeed.io](https://www.sitespeed.io/).

In addition to the above we have experimental [Scenario](../k6/tests/scenarios) tests that aim to represent a complete user scenario (e.g. creating a new issue) and [Quarantined](../k6/tests/quarantined) tests due to some ongoing issue with endpoint or test itself (that don't run unless specifically instructed).

## Running the Tests with the Tool

When all of the above configuration is in place the tests can be run with the tool. This can be done in one of two ways - With our [Docker image](https://hub.docker.com/r/gitlab/gitlab-performance-tool) (recommended) or natively on a Linux based system.

### Docker (Recommended)

The recommended way to run the Tool is with our Docker image, [gitlab/gitlab-performance-tool](https://hub.docker.com/r/gitlab/gitlab-performance-tool) (alternative mirror: [registry.gitlab.com/gitlab-org/quality/performance/gitlab-performance-tool](https://gitlab.com/gitlab-org/quality/performance/container_registry)), which will be regularly updated with new features and tests. It can also be used in offline environments.

The image will start running the tests when it's called. The full options for running the tool can be seen by getting the help output by running `docker run -it gitlab/gitlab-performance-tool --help`:

```
GitLab Performance Tool (GPT) v1.1.0 - Performance test runner for GitLab environments based on k6

Documentation: https://gitlab.com/gitlab-org/quality/performance/blob/master/docs/README.md

Usage: run-k6 [options]
Options:
  -h, --help               Show this help message
  -e, --environment=<s>    Name of Environment Config file in environments directory that the test(s) will be run with. Alternative filepath can also be given.
  -o, --options=<s>        Name of Options Config file in options directory that the test(s) will be run with. Alternative filepath can also be given. (Default: 20s_2rps.json)
  -t, --tests=<s+>         Names of Test files or directories to run with. When directory given tests will be recursively added from api, web and git subdirs (default: tests)
  -s, --scenarios          Include any tests inside the test directory's scenarios subfolder when true.
  -q, --quarantined        Include any tests inside the test directory's quarantined subfolder when true.
  -x, --excludes=<s+>      List of words used to exclude tests by matching against their names. (Default: )
  -r, --read-only          Enable read-only mode to run tests with only GET requests

Environment Variable(s):
  ACCESS_TOKEN             A valid GitLab Personal Access Token for the specified environment that's required by various tests. The token should come from a User that has admin access for
the project(s) to be tested and have API and read_repository permissions. (Default: nil)

Examples:
  Run all Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json
  Run all API Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api
  Run a specific Test with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api_v4_groups_projects.js
  -v, --version            Print version and exit
```

The only further setup required to run the tests is to provide any of your custom Environment, Options and Test files to the container via volume mounts as well as provide a mount for results to be saved to on the host. 

Here's an example of how you would run the Docker image with all pieces of config being passed (replacing placeholders as appropriate):

```
docker run -it -e ACCESS_TOKEN=<TOKEN> -v <HOST ENVIRONMENT CONFIG FOLDER>:/environments -v <HOST OPTIONS CONFIG FOLDER>:/options -v <HOST TESTS FOLDER>:/tests -v <HOST RESULTS FOLDER>:/results gitlab/gitlab-performance-tool --environment <ENV FILE NAME>.json --options 60s_500rps.json --tests api_v4_groups_projects.js
```

After running the results will be in the folder you mounted. More details on the results can be found in the [Test Output and Results](#test-output-and-results).

### Linux

You can also run the tool natively on a Linux machine with some caveats:

* The tool has been tested on Debian and Alpine based distros (but it should be able to run on others as well).
* This method will require the machine running the tool to have internet access to install Ruby Gems and k6 (if not already present).

Before running some setup is required for tool's Ruby Gems:

1. First, set up [`Ruby`](https://www.ruby-lang.org/en/documentation/installation/) and [`Ruby Bundler`](https://bundler.io) if they aren't already available on the machine.
1. Next, install the required Ruby Gems via Bundler
    * `bundle install`

Next you would need to add any of your custom Environment, Options and Test files to their respective directories. From the tool's root folder this would be `k6/environments`, `k6/options` and `k6/tests` respectively.

Once setup is done you can run the tool with the `bin/run-k6` script. The options for running the tests are the same as when running in Docker but the examples change to the following:

```
Examples:
  Run all Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json
  Run all API Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api
  Run a specific Test with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api_v4_groups_projects.js
```

After running the results will be in the tool's `k6/results` folder. More details on the results can be found in the [Test Output and Results](#test-output-and-results).

### Test Output and Results

After starting the tool you will see it running each test in order. As an example this, the output for the [api_v4_groups_projects](../k6/tests/api/api_v4_groups_projects.js) test would look similar to the following:

```
GitLab Performance Tool (GPT) v1.1.0 - Performance test runner for GitLab environments based on k6

Saving all test results to k6/results/10k_v12-7-0-pre_2020-01-30_134333
Running k6 test 'api_v4_groups_projects' against environment '10k'...

          /\      |‾‾|  /‾‾/  /‾/
     /\  /  \     |  |_/  /  / /
    /  \/    \    |      |  /  ‾‾\
   /          \   |  |‾\  \ | (_) |
  / __________ \  |__|  \__\ \___/ .io

  execution: local--------------------------------------------------]   servertor
     output: -
     script: k6/tests/api/api_v4_groups_projects.js

    duration: -, iterations: -
         vus: 1, max: 200

time="2020-01-30T13:43:39Z" level=info------------------------------] starting
time="2020-01-30T13:43:39Z" level=info msg="RPS Threshold: 160.00/s (9600)"
time="2020-01-30T13:43:39Z" level=info msg="Success Rate Threshold: 95%"
time="2020-01-30T13:43:40Z" level=info msg=Running i=91 t=976.07394ms
time="2020-01-30T13:43:41Z" level=info msg=Running i=297 t=1.976059234s
time="2020-01-30T13:43:42Z" level=info msg=Running i=496 t=2.976066351s
time="2020-01-30T13:43:43Z" level=info msg=Running i=703 t=3.976128993s
time="2020-01-30T13:43:44Z" level=info msg=Running i=901 t=4.976071844s
time="2020-01-30T13:43:45Z" level=info msg=Running i=1100 t=5.976055361s
time="2020-01-30T13:43:46Z" level=info msg=Running i=1303 t=6.976066847s
time="2020-01-30T13:43:47Z" level=info msg=Running i=1501 t=7.976074869s
time="2020-01-30T13:43:48Z" level=info msg=Running i=1702 t=8.976136087s
time="2020-01-30T13:43:49Z" level=info msg=Running i=1900 t=9.976069262s
time="2020-01-30T13:43:50Z" level=info msg=Running i=2101 t=10.976074184s
time="2020-01-30T13:43:51Z" level=info msg=Running i=2300 t=11.976079467s
time="2020-01-30T13:43:52Z" level=info msg=Running i=2505 t=12.976065389s
time="2020-01-30T13:43:53Z" level=info msg=Running i=2704 t=13.976075398s
time="2020-01-30T13:43:54Z" level=info msg=Running i=2901 t=14.976076174s
time="2020-01-30T13:43:55Z" level=info msg=Running i=3102 t=15.976067349s
time="2020-01-30T13:43:56Z" level=info msg=Running i=3302 t=16.976068175s
time="2020-01-30T13:43:57Z" level=info msg=Running i=3503 t=17.976077332s
time="2020-01-30T13:43:58Z" level=info msg=Running i=3701 t=18.976071144s
time="2020-01-30T13:43:59Z" level=info msg=Running i=3903 t=19.97606391s
time="2020-01-30T13:44:00Z" level=info msg=Running i=4101 t=20.976081216s
time="2020-01-30T13:44:01Z" level=info msg=Running i=4300 t=21.976060059s
time="2020-01-30T13:44:02Z" level=info msg=Running i=4499 t=22.97607213s
time="2020-01-30T13:44:03Z" level=info msg=Running i=4701 t=23.976098305s
time="2020-01-30T13:44:04Z" level=info msg=Running i=4903 t=24.97607358s
time="2020-01-30T13:44:05Z" level=info msg=Running i=5100 t=25.976063702s
time="2020-01-30T13:44:06Z" level=info msg=Running i=5305 t=26.976085025s
time="2020-01-30T13:44:07Z" level=info msg=Running i=5502 t=27.976074638s
time="2020-01-30T13:44:08Z" level=info msg=Running i=5701 t=28.976076142s
time="2020-01-30T13:44:09Z" level=info msg=Running i=5902 t=29.976086777s
time="2020-01-30T13:44:10Z" level=info msg=Running i=6104 t=30.976067171s
time="2020-01-30T13:44:11Z" level=info msg=Running i=6303 t=31.976061724s
time="2020-01-30T13:44:12Z" level=info msg=Running i=6501 t=32.976151701s
time="2020-01-30T13:44:13Z" level=info msg=Running i=6698 t=33.976081967s
time="2020-01-30T13:44:14Z" level=info msg=Running i=6896 t=34.976074076s
time="2020-01-30T13:44:15Z" level=info msg=Running i=7099 t=35.976005889s
time="2020-01-30T13:44:16Z" level=info msg=Running i=7299 t=36.976058641s
time="2020-01-30T13:44:17Z" level=info msg=Running i=7503 t=37.976082373s
time="2020-01-30T13:44:18Z" level=info msg=Running i=7698 t=38.976081435s
time="2020-01-30T13:44:19Z" level=info msg=Running i=7902 t=39.97607643s
time="2020-01-30T13:44:20Z" level=info msg=Running i=8101 t=40.976056685s
time="2020-01-30T13:44:21Z" level=info msg=Running i=8304 t=41.976069992s
time="2020-01-30T13:44:22Z" level=info msg=Running i=8502 t=42.976067696s
time="2020-01-30T13:44:23Z" level=info msg=Running i=8702 t=43.976091691s
time="2020-01-30T13:44:24Z" level=info msg=Running i=8903 t=44.9760687s
time="2020-01-30T13:44:25Z" level=info msg=Running i=9101 t=45.976080695s
time="2020-01-30T13:44:26Z" level=info msg=Running i=9301 t=46.976070094s
time="2020-01-30T13:44:27Z" level=info msg=Running i=9502 t=47.976065509s
time="2020-01-30T13:44:28Z" level=info msg=Running i=9702 t=48.976075522s
time="2020-01-30T13:44:29Z" level=info msg=Running i=9906 t=49.976076684s
time="2020-01-30T13:44:30Z" level=info msg=Running i=10106 t=50.976076075s
time="2020-01-30T13:44:31Z" level=info msg=Running i=10303 t=51.976071358s
time="2020-01-30T13:44:32Z" level=info msg=Running i=10504 t=52.976067836s
time="2020-01-30T13:44:33Z" level=info msg=Running i=10704 t=53.976063739s
time="2020-01-30T13:44:34Z" level=info msg=Running i=10904 t=54.976067524s
time="2020-01-30T13:44:35Z" level=info msg=Running i=11085 t=55.976074209s
time="2020-01-30T13:44:36Z" level=info msg=Running i=11241 t=56.976077742s
time="2020-01-30T13:44:37Z" level=info msg=Running i=11397 t=57.976073115s
time="2020-01-30T13:44:38Z" level=info msg=Running i=11553 t=58.976097437s
time="2020-01-30T13:44:39Z" level=info msg=Running i=11671 t=59.976076995s
time="2020-01-30T13:44:39Z" level=info msg="Test finished" i=11672 t=1m0.000088911s

    █ API - Group Projects List

    data_received..............: 145 MB  2.4 MB/s
    data_sent..................: 1.6 MB  26 kB/s
    group_duration.............: avg=937.00ms min=112.39ms med=990.10ms max=1348.19ms p(90)=1022.20ms p(95)=1047.05ms
    http_req_blocked...........: avg=0.02ms   min=0.00ms   med=0.01ms   max=20.40ms   p(90)=0.01ms    p(95)=0.02ms
    http_req_connecting........: avg=0.01ms   min=0.00ms   med=0.00ms   max=18.51ms   p(90)=0.00ms    p(95)=0.00ms
    http_req_duration..........: avg=140.87ms min=104.45ms med=133.48ms max=525.47ms  p(90)=167.46ms  p(95)=199.82ms
    http_req_receiving.........: avg=0.12ms   min=0.05ms   med=0.11ms   max=2.40ms    p(90)=0.16ms    p(95)=0.18ms
    http_req_sending...........: avg=0.02ms   min=0.01ms   med=0.02ms   max=0.98ms    p(90)=0.03ms    p(95)=0.04ms
    http_req_tls_handshaking...: avg=0.00ms   min=0.00ms   med=0.00ms   max=0.00ms    p(90)=0.00ms    p(95)=0.00ms
    http_req_waiting...........: avg=140.72ms min=104.31ms med=133.33ms max=525.28ms  p(90)=167.31ms  p(95)=199.68ms
  ✓ http_reqs..................: 11672   194.533045/s
    iteration_duration.........: avg=936.94ms min=0.25ms   med=990.13ms max=1348.21ms p(90)=1022.23ms p(95)=1047.07ms
    iterations.................: 11672   194.533045/s
  ✓ successful_requests........: 100.00% ✓ 11672 ✗ 0
    vus........................: 1       min=1   max=200
    vus_max....................: 200     min=200 max=200

All k6 tests have finished after 66.47s!

Known issues:

Note that the following endpoints below have known issues. These tests have either been run with a custom lower threshold limit applied or are quarantined until the issue is fixed:
TEST                                                        | ISSUE
------------------------------------------------------------|-----------------------------------------------------------------------------------------------------
api_v4_projects_merge_requests.js                           | https://gitlab.com/gitlab-org/gitlab/issues/33150, https://gitlab.com/gitlab-org/gitlab/issues/30180
api_v4_projects_merge_requests_merge_request.js             | https://gitlab.com/gitlab-org/gitlab/issues/30507
api_v4_projects_merge_requests_merge_request_discussions.js | https://gitlab.com/gitlab-org/gitlab/issues/32455
api_v4_projects_project_search_blobs.js                     | https://gitlab.com/gitlab-org/gitlab/issues/33562
api_v4_projects_repository_branches.js                      | https://gitlab.com/gitlab-org/gitlab/issues/30536
scenario_api_new_branches.js                                | https://gitlab.com/gitlab-org/gitlab/issues/196788
web_project_branches.js                                     | https://gitlab.com/gitlab-org/gitlab/issues/30536
web_project_commits.js                                      | https://gitlab.com/gitlab-org/gitlab/issues/31321
web_project_merge_request_changes.js                        | https://gitlab.com/gitlab-org/gitlab/issues/30507
web_project_merge_request_commits.js                        | https://gitlab.com/gitlab-org/gitlab/issues/30507
web_project_merge_request_discussions.js                    | https://gitlab.com/gitlab-org/gitlab/issues/30507

Full list of issues found both past and present can be found here: https://gitlab.com/gitlab-org/gitlab/issues?label_name%5B%5D=Quality%3Aperformance-issues

Results summary:

* Environment:                10k
* Environment Version:        12.7.0-pre `60ddd8fb177`
* Option:                     60s_200rps
* Date:                       2020-01-30
* Run Time:                   1m 6.47s (Start: 13:43:33 UTC, End: 13:44:39 UTC)
* GPT Version:                v1.1.0

NAME                   | RPS   | RPS RESULT           | REQ AVG  | REQ P95  | REQ STATUS     | RESULT
-----------------------|-------|----------------------|----------|----------|----------------|----------------
api_v4_groups_projects | 200/s | 194.53/s (>160.00/s) | 140.72ms | 199.68ms | 100.00% (>95%) | Passed

Results files:
k6/results/10k_v12-7-0-pre_2020-01-30_134333/10k_v12-7-0-pre_2020-01-30_134333_results_output.log
k6/results/10k_v12-7-0-pre_2020-01-30_134333/10k_v12-7-0-pre_2020-01-30_134333_results.json
k6/results/10k_v12-7-0-pre_2020-01-30_134333/10k_v12-7-0-pre_2020-01-30_134333_results.txt
```

Once all tests have completed you'll be presented with a results summary. As an example, here is a test summary for tests done against the `10k` environment with detailed explanations after:

```
* Environment:    10k
* Version:        12.7.0-pre `60ddd8fb177`
* Option:         60s_200rps
* Date:           2020-01-30
* Run Time:       44m 18.99s (Start: 11:07:46 UTC, End: 11:52:05 UTC)

NAME                                                     | RPS   | RPS RESULT           | REQ AVG   | REQ P95   | REQ STATUS     | RESULT
---------------------------------------------------------|-------|----------------------|-----------|-----------|----------------|-------
api_v4_groups_group                                      | 200/s | 194.72/s (>160.00/s) | 133.03ms  | 184.34ms  | 100.00% (>95%) | Passed
api_v4_groups_projects                                   | 200/s | 194.83/s (>160.00/s) | 134.46ms  | 177.12ms  | 100.00% (>95%) | Passed
api_v4_projects_deploy_keys                              | 200/s | 196.1/s (>160.00/s)  | 38.16ms   | 43.26ms   | 100.00% (>95%) | Passed
api_v4_projects_languages                                | 200/s | 196.23/s (>160.00/s) | 34.68ms   | 38.65ms   | 100.00% (>95%) | Passed
api_v4_projects_merge_requests                           | 200/s | 191.43/s (>128.00/s) | 362.80ms  | 1053.82ms | 100.00% (>95%) | Passed
api_v4_projects_merge_requests_merge_request             | 200/s | 195.3/s (>160.00/s)  | 91.31ms   | 109.60ms  | 100.00% (>95%) | Passed
api_v4_projects_merge_requests_merge_request_changes     | 200/s | 195.68/s (>160.00/s) | 69.95ms   | 82.31ms   | 100.00% (>95%) | Passed
api_v4_projects_merge_requests_merge_request_commits     | 200/s | 195.78/s (>160.00/s) | 56.36ms   | 66.07ms   | 100.00% (>95%) | Passed
api_v4_projects_merge_requests_merge_request_discussions | 200/s | 91.72/s (>80.00/s)   | 1960.71ms | 3359.00ms | 100.00% (>95%) | Passed
api_v4_projects_pagination_keyset                        | 200/s | 194.43/s (>160.00/s) | 147.90ms  | 220.93ms  | 100.00% (>95%) | Passed
api_v4_projects_pagination_offset                        | 200/s | 194.55/s (>160.00/s) | 153.05ms  | 226.38ms  | 100.00% (>95%) | Passed
api_v4_projects_project                                  | 200/s | 195.37/s (>160.00/s) | 92.03ms   | 110.50ms  | 100.00% (>95%) | Passed
api_v4_projects_project_pipelines                        | 200/s | 195.9/s (>160.00/s)  | 51.61ms   | 60.09ms   | 100.00% (>95%) | Passed
api_v4_projects_project_search_blobs                     | 200/s | 194.42/s (>80.00/s)  | 122.20ms  | 145.47ms  | 100.00% (>95%) | Passed
api_v4_projects_project_services                         | 200/s | 196.25/s (>160.00/s) | 35.74ms   | 40.44ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_branches                      | 200/s | 50.15/s (>8.00/s)    | 3524.71ms | 4954.87ms | 100.00% (>95%) | Passed
api_v4_projects_repository_branches_branch               | 200/s | 195.87/s (>160.00/s) | 53.80ms   | 67.47ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_commits                       | 200/s | 195.85/s (>160.00/s) | 54.27ms   | 62.03ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_commits_sha                   | 200/s | 195.9/s (>160.00/s)  | 53.04ms   | 58.63ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_commits_sha_diff              | 200/s | 195.92/s (>160.00/s) | 51.96ms   | 58.42ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_commits_sha_signature         | 200/s | 195.93/s (>160.00/s) | 46.43ms   | 51.79ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_files_file                    | 200/s | 195.55/s (>160.00/s) | 69.10ms   | 77.56ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_files_file_raw                | 200/s | 195.55/s (>160.00/s) | 73.65ms   | 82.71ms   | 100.00% (>95%) | Passed
api_v4_projects_repository_tree                          | 200/s | 195.88/s (>160.00/s) | 54.28ms   | 61.10ms   | 100.00% (>95%) | Passed
api_v4_user                                              | 200/s | 196.17/s (>160.00/s) | 29.15ms   | 32.26ms   | 100.00% (>95%) | Passed
git_ls_remote                                            | 20/s  | 19.63/s (>16.00/s)   | 47.36ms   | 63.55ms   | 100.00% (>95%) | Passed
git_pull                                                 | 20/s  | 19.7/s (>16.00/s)    | 63.89ms   | 98.35ms   | 100.00% (>95%) | Passed
scenario_api_new_branches                                | 10/s  | 9.35/s (>8.00/s)     | 792.38ms  | 880.94ms  | 100.00% (>95%) | Passed
scenario_api_new_issues                                  | 10/s  | 9.8/s (>8.00/s)      | 190.82ms  | 302.17ms  | 100.00% (>95%) | Passed
web_group                                                | 20/s  | 19.33/s (>16.00/s)   | 90.91ms   | 168.60ms  | 100.00% (>95%) | Passed
web_project                                              | 20/s  | 19.2/s (>16.00/s)    | 270.80ms  | 346.47ms  | 100.00% (>95%) | Passed
web_project_blob_file                                    | 20/s  | 19.27/s (>16.00/s)   | 198.30ms  | 299.89ms  | 100.00% (>95%) | Passed
web_project_branches                                     | 20/s  | 18.57/s (>9.60/s)    | 756.06ms  | 890.05ms  | 100.00% (>95%) | Passed
web_project_commits                                      | 20/s  | 19.0/s (>16.00/s)    | 471.41ms  | 538.08ms  | 100.00% (>95%) | Passed
web_project_files                                        | 20/s  | 19.25/s (>16.00/s)   | 260.23ms  | 325.31ms  | 100.00% (>95%) | Passed
web_project_merge_request_changes                        | 20/s  | 4.28/s (>2.40/s)     | 4043.96ms | 9087.14ms | 100.00% (>95%) | Passed
web_project_merge_request_commits                        | 20/s  | 18.98/s (>9.60/s)    | 539.80ms  | 935.47ms  | 100.00% (>95%) | Passed
web_project_merge_request_discussions                    | 20/s  | 18.57/s (>11.20/s)   | 927.91ms  | 2699.43ms | 100.00% (>95%) | Passed
web_project_merge_requests                               | 20/s  | 19.25/s (>16.00/s)   | 224.31ms  | 326.82ms  | 100.00% (>95%) | Passed
web_project_pipelines                                    | 20/s  | 19.25/s (>16.00/s)   | 245.27ms  | 407.77ms  | 100.00% (>95%) | Passed
web_user                                                 | 20/s  | 19.4/s (>16.00/s)    | 62.07ms   | 91.23ms   | 100.00% (>95%) | Passed
```

* `NAME` - The name of the test run. Matches the filename of the test as found in the [`tests`](../k6/tests) folder
* `RPS` - The RPS target used during the test.
* `RPS RESULT` - The average RPS the test was able to achieve throughout it's run along with it's passing threshold.
* `REQ AVG` - The average of the response times seen by the test.
* `REQ P95` - The 95th [percentile](https://en.wikipedia.org/wiki/Percentile_rank) of the response times seen by the test.
* `REQ STATUS` - The percentage of requests made by the test that returned a successful status (HTTP Code 200 / 201 returned) along with it's passing threshold.
* `RESULT` - The final result of the test based on it's thresholds.

As described above there are several thresholds that determine if the test has passed or not:

* RPS achieved by the test is above it's target. The threshold is typically the target RPS (with a 20% buffer to account for network or other quirks) by default but tests can have their own different thresholds set depending on the area they are testing. Refer to each test to confirm thresholds.
* TTFB (Time to first byte) response time is below thresholds set in reach test. This is a new threshold and being rolled out to tests incrementally.
* That more than 95% of all requests made were successful (HTTP Code 200 / 201 returned).

More information on the results output from `k6` can be found over on it's documentation - [Results output](https://docs.k6.io/docs/results-output).

#### Evaluating Failures

If any of the tests report RPS threshold failures these should be evaluated accordingly in line with the following:

* If any of the tests failed but only by a small amount (e.g. within 10% of the threshold) this is likely due to environmental or network conditions such as latency. As such, these can typically can be ignored if multiple sets of test runs report the same level of failures consistently. If seeking confidence the tests can be run again with a slightly lower RPS threshold modifier to confirm.
* If the failures are substantial (e.g. over 50% of the threshold) this would suggest an environment or product issue and further investigation may be required and should be escalated through the [appropriate channels](https://about.gitlab.com/support/) (e.g. A support ticket or an issue raised against the main GitLab project).

If any of the tests report more than 5% of failed requests outright this should be treated the same as a substantial RPS failure above and escalated through similar channels. A common example of this kind of failure is multiple http 500 code errors being thrown by areas that are completely unable to handle the expected throughput and subsequently failing completely.

#### Comparing Results

We post our own results over on this [project's wiki](https://gitlab.com/gitlab-org/quality/performance/wikis/home) for transparency as well as allowing users to compare. 

Currently, you'll find the following results on our Wiki:
* [Latest Results](https://gitlab.com/gitlab-org/quality/performance/wikis/Benchmarks/Latest) - Our automated CI pipelines run multiple times each week and will post their result summaries to the wiki here each time.
* [GitLab Versions](https://gitlab.com/gitlab-org/quality/performance/wikis/Benchmarks/GitLab-Versions) - A collection of performance test results done against several select release versions of GitLab.

## Troubleshooting

In this section we'll detail any known potential problems when running `k6` and how to manage them.

### `socket: too many open files`

You may see `k6` throw the error `socket: too many open files` many times if you're running a test with particularly high amount of virtual users and throughput, e.g. More than 200 users / RPS.

When this happens it's due to the underlying OS having a limit for how many files can be open at one time, also known as file descriptors. This can be fixed by increasing the number of files that are allowed to be open in the OS. How this is done typically is dependent on the type and version of the OS and you should refer to it's documentation. For example though here are links on how to normally do this on [Linux](https://www.tecmint.com/increase-set-open-file-limits-in-linux/) and [Mac OS](https://medium.com/mindful-technology/too-many-open-files-limit-ulimit-on-mac-os-x-add0f1bfddde) respectively. Another workaround is to run the tests in Docker, which typically have higher limits by default.
