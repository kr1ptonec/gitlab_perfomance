# GitLab Performance Tool - Running Tests

On this page, we'll detail how to setup the Tool, how to configure the tests and then how to run them.

**Note: Before running any tests with the Tool, the intended GitLab environment should be prepared first. Details on how to do this can be found here: [GitLab Performance Tool - Environment Preparation](environment_prep.md)**

* [Tool Setup](#tool-setup)
* [Test Configuration](#test-configuration)
  * [Environments](#environments)
  * [Options](#options)
  * [Tests](#tests)
* [Running Tests](#running-tests)
  * [Troubleshooting](#troubleshooting)
    * [`socket: too many open files`](#socket-too-many-open-files)
* [Test Results](#test-results)
  * [Evaluating Failures](#evaluating-failures)
  * [Comparing Results](#comparing-results)

## Tool Setup

On the machine that will be running the tests the following setup is required:

1. First, set up [`Ruby`](https://www.ruby-lang.org/en/documentation/installation/) and [`Ruby Bundler`](https://bundler.io) if they aren't already available on the machine.
1. Next, install the required Ruby Gems via Bundler
    * `bundle install`

**Note: The runner script will install `k6` (which this tool is based on) to the system temp folder if it's not already installed on the machine or if it's the wrong version**

## Test Configuration

Out of the box all the k6 tests are configured to run against a GitLab environment that at least has one instance of the default Test Project setup (see [GitLab Performance Tool - Environment Preparation](environment_prep.md) for more info).

If you are looking to run the tests against your own Environment(s), Test Project(s) or if you want to define new Option(s) this section aims to take you through all relevant areas of config and how to set them accordingly.

The k6 tests have a few key areas of configuration - [Environments](../k6/environments), [Options](../k6/options) and [Tests](../k6/tests):

### Environments

The k6 tests require configuration to be passed that sets the environment to be tested along with project(s) details that the tests will expect and use accordingly. This is done with an [Environment Config File](../k6/environments) in JSON format.

As an example, the following is one of our Environment Config Files - [`10k.json`](../k6/environments/10k.json) - with detailed explanations:

```json
{
  "environment": {
    "name": "10k",
    "url": "http://10k.testbed.gitlab.net"
  },
  "projects": [
    {
      "name": "gitlabhq",
      "group": "qa-perf-testing",
      "commit_sha": "0a99e022",
      "commit_sha_signed": "6526e91f",
      "branch": "10-0-stable",
      "file_path": "qa%2fqa%2erb",
      "mr_commits_iid": "10495",
      "mr_discussions_iid": "6958"
    },
    {
      "name": "gitlabhq2",
      "group": "qa-perf-testing",
      "commit_sha": "0a99e022",
      "commit_sha_signed": "6526e91f",
      "branch": "10-0-stable",
      "file_path": "qa%2fqa%2erb",
      "mr_commits_iid": "10495",
      "mr_discussions_iid": "6958"
    }
  ]
}
```

* The environment's Name and URL.
    * Note as a convenience these two settings can also be defined as environment variables, `ENVIRONMENT_NAME` and `ENVIRONMENT_URL` respectively, for overriding as required.
* Details for each project that the tests can target. Each project is expected to have the following defined:
    * `name` - Name of the Project.
    * `group` - The name of the Group that contains the intended Project.
    * `commit_sha` - The SHA reference of a large commit available in the project. The size of the commit should be tuned to your environment's requirements.
    * `commit_sha_signed` - The SHA reference of a [signed commit](https://docs.gitlab.com/ee/user/project/repository/gpg_signed_commits/) available in the project.
    * `branch` - The name of a large branch available in the project. The size of the branch should be tuned to your environment's requirements.
    * `file_path` - The relative path to a normal sized file in your project.
    * `mr_commits_iid` - The [iid](https://docs.gitlab.com/ee/api/#id-vs-iid) of a merge request available in the project that has a large number of commits. The size of the MR should be tuned to your environment's requirements.
    * `mr_discussions_iid` - The [iid](https://docs.gitlab.com/ee/api/#id-vs-iid) of a merge request available in the project that has a large number of discussions / comments. The size of the MR discussions should be tuned to your environment's requirements.
  
> Note that all of the above variables are required

### Options

The k6 tests also require the Options that they will be run with to be set, e.g. how long to run the tests for, how many users and how much throughput. These can be set in one of two ways - By setting them in a [Options Config File](../k6/options) (recommended) or in the test scripts themselves.

The [Options Config Files](../k6/options) are themselves native [k6 config files](https://docs.k6.io/docs/options). For this tool, we use them to set options but they can also be used to set any valid k6 options as required.

As an example, the following is one of our Options Config Files, [`20s_2rps.json`](../k6/options/20s_2rps.json), with detailed explanations:

```json
{
  "userAgent": "GitlabK6PerformanceTest/1.0",
  "stages": [
    { "duration": "5s", "target": 2 },
    { "duration": "15s", "target": 2 }
  ],
  "rps": 2
}
```

* `userAgent` - A custom User Agent for the tests to use to allow for easier identification in application logs. This is optional and only used for debugging purposes.
* `stages` - Defines the stages k6 should run the tests with. Sets the duration of each stage and how many users (VUs) to use. 
    * It should be noted that each stage will ramp up from the previous, so in this example the scenario is to ramp up from 0 to 2 users over 5 seconds and then maintain 2 users for another 15s.
* `rps` - Sets the maximum Requests per Second that k6 can make in total.

> Note that it's best practice to set the number of users (VUs) to the same amount as RPS.

### Tests

Finally we have the k6 test scripts themselves. Each file contains a test to run against the environment along with any extra config such as setting thresholds.

To get more detailed information about the current test list you can refer to the [Current Test Details wiki page](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details).

Like Options, test files are native [k6 test scripts](https://docs.k6.io/docs/running-k6#section-executing-local-scripts) and all valid k6 features and options can be used here.

With the tool, we provide various curated tests that are designed to test a wide range of GitLab functions. In each we set the actions to take (e.g. call an API) along with defining thresholds that determine if the test is a success (e.g. actual RPS should be no less than 20% of the target and no more than 5% of requests made can be failures).

As an example, the following is one of our Tests, [`api_v4_projects_project.js`](../k6/tests/api/api_v4_projects_project.js), with detailed explanation:

```js
/*global __ENV : true  */
/*
@endpoint: `GET /projects/:id`
@description: [Get single project](https://docs.gitlab.com/ee/api/projects.html#get-single-project)
*/

import http from "k6/http";
import { group, fail } from "k6";
import { Rate } from "k6/metrics";
import { logError, getRpsThresholds, getProjects, selectProject } from "../../lib/k6_test_modules.js";

if (!__ENV.ACCESS_TOKEN) fail('ACCESS_TOKEN has not been set. Skipping...')

export let rpsThresholds = getRpsThresholds()
export let successRate = new Rate("successful_requests");
export let options = {
  thresholds: {
    "successful_requests": [`rate>${__ENV.SUCCESS_RATE_THRESHOLD}`],
    "http_reqs": [`count>=${rpsThresholds['count']}`]
  }
};

export let projects = getProjects();

export function setup() {
  console.log('')
  console.log(`RPS Threshold: ${rpsThresholds['mean']}/s (${rpsThresholds['count']})`)
  console.log(`Success Rate Threshold: ${parseFloat(__ENV.SUCCESS_RATE_THRESHOLD)*100}%`)
}

export default function() {
  group("API - Project Overview", function() {
    let project = selectProject(projects);

    let params = { headers: { "Accept": "application/json", "PRIVATE-TOKEN": `${__ENV.ACCESS_TOKEN}` } };
    let res = http.get(`${__ENV.ENVIRONMENT_URL}/api/v4/projects/${project['group']}%2F${project['name']}`, params);
    /20(0|1)/.test(res.status) ? successRate.add(true) : successRate.add(false) && logError(res);
  });
}
```

The above script is to test the Projects API, namely to [get the details of a specific project](https://docs.gitlab.com/ee/api/projects.html#get-single-project).

The script does the following:
* Informs `eslint` that global environment variables are to be used
* Sets some custom labels describing the test that are used by GitLab Quality for [reporting](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details).
* Imports the various k6 libraries and our own custom modules that we use in the script
* Fails the test if the `ACCESS_TOKEN` environment variable hasn't be set on the machine as this test requires it to authenticate. (more details on the token can be found in the [Running Tests](#running-tests) section)
* Configures the Thresholds that will be used to determine if the test has passed or not (more details on the thresholds can be found in the [Test Results](#test-results) section)
* Loads in the Projects defined in the Environment config file
* Logs some useful info that the wrapper tool will use for reporting
* Finally the main test script itself is last. It selects a Project at random, sets the required headers and then calls the endpoint on the Environment. It then checks if the response was valid, adds the result to the threshold and calls our custom module to report any errors once in the test output.

> Note that the above is an example of a typical test. Other [tests](https://gitlab.com/gitlab-org/quality/performance/wikis/current-test-details) may vary in their approach depending on the area being targeted.

## Running Tests

With the Environment prepared and Tests configured, the tests can now be run with the [`run-k6`](../bin/run-k6) wrapper tool.

Below is the help output for the tool and how it can be used to run the tests. In this example we're running the tool from the [`root`](..) folder with relative paths shown:

```
Usage: run-k6 [options]

Runs k6 Test(s) with the given Options against the specified Environment.

Options:
  -h, --help               Show this help message
  -e, --environment=<s>    Name of Environment Config file in k6/environments directory that the test(s) will be run with.
                           Alternative filepath can also be given.
  -o, --options=<s>        Name of Options Config file in k6/options directory that the test(s) will be run with.
                           Alternative filepath can also be given. (Default: 20s_2rps.json)
  -t, --tests=<s+>         Names of Test files or directories to run with. When directory given tests will be recursively
                           added from api, web and git subdirs (default: k6/tests)
  -c, --custom             Include any tests inside the test directory's custom subfolder when true.
  -s, --scenarios          Include any tests inside the test directory's scenarios subfolder when true.
  -q, --quarantined        Include any tests inside the test directory's quarantined subfolder when true.
  -p, --http-debug         Enable k6 HTTP debug logs in output
  -x, --excludes=<s+>      List of words used to exclude tests by matching against their names. (Default: )

Environment Variable(s):
  ACCESS_TOKEN             A valid GitLab Personal Access Token for the specified environment that's required by various
tests. The token should come from a User that has admin access for the project(s) to be tested and have API and
read_repository permissions. (Default: nil)

Examples:
  Run all Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json
  Run all Tests including any in custom subfolder with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --custom
  Run all API Tests with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api
  Run a specific Test with the 60s_200rps Options file against the 10k Environment:
    ./bin/run-k6 --environment 10k.json --options 60s_200rps.json --tests api_v4_groups_projects.js
```

Taking the example above of running the test `api_v4_groups_projects.js`, the output you should see would be as follows:
```
GitLab Performance Tool - k6 load test runner

Saving all test results to k6/results/10k_v12-6-0-pre_2019-11-27_124004
Running k6 test 'api_v4_groups_projects' against environment '10k'...

          /\      |‾‾|  /‾‾/  /‾/
     /\  /  \     |  |_/  /  / /
    /  \/    \    |      |  /  ‾‾\
   /          \   |  |‾\  \ | (_) |
  / __________ \  |__|  \__\ \___/ .io

  execution: local--------------------------------------------------]   servertor
     output: -
     script: k6/tests/api/api_v4_groups_projects.js

    duration: -, iterations: -
         vus: 1, max: 200

time="2019-11-27T12:40:07Z" level=info------------------------------] starting
time="2019-11-27T12:40:07Z" level=info msg="RPS Threshold: 160.00/s (9600)"
time="2019-11-27T12:40:07Z" level=info msg="Success Rate Threshold: 95%"
time="2019-11-27T12:40:08Z" level=info msg=Running i=7 t=985.260961ms
time="2019-11-27T12:40:09Z" level=info msg=Running i=31 t=1.985261582s
time="2019-11-27T12:40:10Z" level=info msg=Running i=74 t=2.983214913s
time="2019-11-27T12:40:11Z" level=info msg=Running i=132 t=3.983220531s
time="2019-11-27T12:40:12Z" level=info msg=Running i=206 t=4.983036809s
time="2019-11-27T12:40:13Z" level=info msg=Running i=332 t=5.983187347s
time="2019-11-27T12:40:14Z" level=info msg=Running i=532 t=6.987067212s
time="2019-11-27T12:40:15Z" level=info msg=Running i=739 t=7.983050242s
time="2019-11-27T12:40:16Z" level=info msg=Running i=933 t=8.988238746s
time="2019-11-27T12:40:17Z" level=info msg=Running i=1134 t=9.983203207s
time="2019-11-27T12:40:18Z" level=info msg=Running i=1336 t=10.983059017s
time="2019-11-27T12:40:19Z" level=info msg=Running i=1535 t=11.988115501s
time="2019-11-27T12:40:20Z" level=info msg=Running i=1738 t=12.985034422s
time="2019-11-27T12:40:21Z" level=info msg=Running i=1936 t=13.984039964s
time="2019-11-27T12:40:22Z" level=info msg=Running i=2135 t=14.985258781s
time="2019-11-27T12:40:23Z" level=info msg=Running i=2333 t=15.984014798s
time="2019-11-27T12:40:24Z" level=info msg=Running i=2539 t=16.984054146s
time="2019-11-27T12:40:25Z" level=info msg=Running i=2737 t=17.987263417s
time="2019-11-27T12:40:26Z" level=info msg=Running i=2939 t=18.985115417s
time="2019-11-27T12:40:27Z" level=info msg=Running i=3138 t=19.986199641s
time="2019-11-27T12:40:28Z" level=info msg=Running i=3338 t=20.986021667s
time="2019-11-27T12:40:29Z" level=info msg=Running i=3541 t=21.98629417s
time="2019-11-27T12:40:30Z" level=info msg=Running i=3738 t=22.98604268s
time="2019-11-27T12:40:31Z" level=info msg=Running i=3939 t=23.986194389s
time="2019-11-27T12:40:32Z" level=info msg=Running i=4135 t=24.983204642s
time="2019-11-27T12:40:33Z" level=info msg=Running i=4340 t=25.98719541s
time="2019-11-27T12:40:34Z" level=info msg=Running i=4539 t=26.986031121s
time="2019-11-27T12:40:35Z" level=info msg=Running i=4735 t=27.983245724s
time="2019-11-27T12:40:36Z" level=info msg=Running i=4935 t=28.983252145s
time="2019-11-27T12:40:37Z" level=info msg=Running i=5139 t=29.986196243s
time="2019-11-27T12:40:38Z" level=info msg=Running i=5339 t=30.987212794s
time="2019-11-27T12:40:39Z" level=info msg=Running i=5538 t=31.988147505s
time="2019-11-27T12:40:40Z" level=info msg=Running i=5739 t=32.98806062s
time="2019-11-27T12:40:41Z" level=info msg=Running i=5939 t=33.986171374s
time="2019-11-27T12:40:42Z" level=info msg=Running i=6137 t=34.984049459s
time="2019-11-27T12:40:43Z" level=info msg=Running i=6336 t=35.983213925s
time="2019-11-27T12:40:44Z" level=info msg=Running i=6540 t=36.988078769s
time="2019-11-27T12:40:45Z" level=info msg=Running i=6737 t=37.983112874s
time="2019-11-27T12:40:46Z" level=info msg=Running i=6938 t=38.985140514s
time="2019-11-27T12:40:47Z" level=info msg=Running i=7136 t=39.986267547s
time="2019-11-27T12:40:48Z" level=info msg=Running i=7336 t=40.985291472s
time="2019-11-27T12:40:49Z" level=info msg=Running i=7535 t=41.983206733s
time="2019-11-27T12:40:50Z" level=info msg=Running i=7737 t=42.984041446s
time="2019-11-27T12:40:51Z" level=info msg=Running i=7939 t=43.984028154s
time="2019-11-27T12:40:52Z" level=info msg=Running i=8137 t=44.983123834s
time="2019-11-27T12:40:53Z" level=info msg=Running i=8340 t=45.985089579s
time="2019-11-27T12:40:54Z" level=info msg=Running i=8538 t=46.984025419s
time="2019-11-27T12:40:55Z" level=info msg=Running i=8738 t=47.983096303s
time="2019-11-27T12:40:56Z" level=info msg=Running i=8939 t=48.983046312s
time="2019-11-27T12:40:57Z" level=info msg=Running i=9141 t=49.983071044s
time="2019-11-27T12:40:58Z" level=info msg=Running i=9340 t=50.987015795s
time="2019-11-27T12:40:59Z" level=info msg=Running i=9539 t=51.9830715s
time="2019-11-27T12:41:00Z" level=info msg=Running i=9736 t=52.983065731s
time="2019-11-27T12:41:01Z" level=info msg=Running i=9936 t=53.985294952s
time="2019-11-27T12:41:02Z" level=info msg=Running i=10135 t=54.983015919s
time="2019-11-27T12:41:03Z" level=info msg=Running i=10339 t=55.983067016s
time="2019-11-27T12:41:04Z" level=info msg=Running i=10541 t=56.983018797s
time="2019-11-27T12:41:05Z" level=info msg=Running i=10742 t=57.983012303s
time="2019-11-27T12:41:06Z" level=info msg=Running i=10936 t=58.983053522s
time="2019-11-27T12:41:07Z" level=info msg=Running i=11140 t=59.986025233s
time="2019-11-27T12:41:07Z" level=info msg="Test finished" i=11143 t=1m0.000066141s

    █ API - Group Projects List

    data_received..............: 70 MB   1.2 MB/s
    data_sent..................: 1.7 MB  28 kB/s
    group_duration.............: avg=942.22ms min=187.79ms med=989.56ms max=1209.21ms p(90)=1034.85ms p(95)=1058.86ms
    http_req_blocked...........: avg=2.06ms   min=0.00ms   med=0.00ms   max=122.50ms  p(90)=0.01ms    p(95)=0.01ms
    http_req_connecting........: avg=2.05ms   min=0.00ms   med=0.00ms   max=122.45ms  p(90)=0.00ms    p(95)=0.00ms
    http_req_duration..........: avg=226.53ms min=184.77ms med=219.30ms max=450.52ms  p(90)=265.12ms  p(95)=288.96ms
    http_req_receiving.........: avg=0.72ms   min=0.04ms   med=0.68ms   max=8.47ms    p(90)=0.91ms    p(95)=0.95ms
    http_req_sending...........: avg=0.02ms   min=0.01ms   med=0.01ms   max=0.43ms    p(90)=0.02ms    p(95)=0.03ms
    http_req_tls_handshaking...: avg=0.00ms   min=0.00ms   med=0.00ms   max=0.00ms    p(90)=0.00ms    p(95)=0.00ms
    http_req_waiting...........: avg=225.80ms min=183.88ms med=218.56ms max=449.97ms  p(90)=264.32ms  p(95)=288.30ms
  ✓ http_reqs..................: 11143   185.716462/s
    iteration_duration.........: avg=942.15ms min=0.17ms   med=989.57ms max=1209.22ms p(90)=1034.85ms p(95)=1058.88ms
    iterations.................: 11143   185.716462/s
  ✓ successful_requests........: 100.00% ✓ 11143 ✗ 0
    vus........................: 200     min=4   max=200
    vus_max....................: 200     min=200 max=200

All k6 tests have finished after 63.47s!

Results summary:

Environment:    10k
Version:        12.6.0-pre 9580c728dbc
Option:         60s_200rps
Date:           2019-11-27
Run Time:       63.47s (Start: 12:40:04 UTC, End: 12:41:07 UTC)

NAME                   | RPS   | RPS RESULT           | RESPONSE P95 | REQUEST RESULTS | RESULT
-----------------------|-------|----------------------|--------------|-----------------|-------
api_v4_groups_projects | 200/s | 185.72/s (>160.00/s) | 288.96ms     | 100.00% (>95%)  | Passed

Results files:
k6/results/10k_v12-6-0-pre_2019-11-27_124004/10k_v12-6-0-pre_2019-11-27_124004_results.json
k6/results/10k_v12-6-0-pre_2019-11-27_124004/10k_v12-6-0-pre_2019-11-27_124004_results.txt
```

### Troubleshooting

In this section we'll detail any known potential problems when running `k6` and how to manage them.

#### `socket: too many open files`

You may see `k6` throw the error `socket: too many open files` many times if you're running a test with particularly high amount of virtual users and throughput, e.g. More than 200 users / RPS.

When this happens it's due to the underlying OS having a limit for how many files can be open at one time, also known as file descriptors. This can be fixed by increasing the number of files that are allowed to be open in the OS. How this is done typically is dependent on the type and version of the OS and you should refer to it's documentation. For example though here are links on how to normally do this on [Linux](https://www.tecmint.com/increase-set-open-file-limits-in-linux/) and [Mac OS](https://medium.com/mindful-technology/too-many-open-files-limit-ulimit-on-mac-os-x-add0f1bfddde) respectively. Another workaround is to run the tests in Docker, which typically have higher limits by default.

## Test Results

Once all tests have completed you'll be presented with a test summary that is also saved in the `results` folder. As an example here is a test summary for tests done against the `10k` environment with detailed explanations after:

```
Environment:    10k (12.4.1-ee 8953eae82c8)
Option:         60s_200rps
Date:           2019-11-01
Run Time:       1655.04s (Start: 02:12:30 UTC, End: 02:40:05 UTC)

NAME                                                     | RPS   | RPS RESULT           | RESPONSE P95 | REQUEST RESULTS | RESULT
---------------------------------------------------------|-------|----------------------|--------------|-----------------|-------
api_v4_groups_group                                      | 200/s | 185.08/s (>160.00/s) | 190.18ms     | 100.00% (>95%)  | Passed
api_v4_groups_projects                                   | 200/s | 189.92/s (>160.00/s) | 190.87ms     | 100.00% (>95%)  | Passed
api_v4_new_issues                                        | 10/s  | 9.22/s (>8.00/s)     | 565.43ms     | 100.00% (>95%)  | Passed
api_v4_projects_deploy_keys                              | 200/s | 195.17/s (>160.00/s) | 66.08ms      | 100.00% (>95%)  | Passed
api_v4_projects_languages                                | 200/s | 195.38/s (>160.00/s) | 49.16ms      | 100.00% (>95%)  | Passed
api_v4_projects_merge_requests                           | 200/s | 62.43/s (>40.00/s)   | 4185.49ms    | 100.00% (>95%)  | Passed
api_v4_projects_merge_requests_merge_request             | 200/s | 191.4/s (>160.00/s)  | 133.26ms     | 100.00% (>95%)  | Passed
api_v4_projects_merge_requests_merge_request_changes     | 200/s | 192.33/s (>160.00/s) | 119.71ms     | 100.00% (>95%)  | Passed
api_v4_projects_merge_requests_merge_request_commits     | 200/s | 22.52/s (>16.00/s)   | 13613.91ms   | 100.00% (>95%)  | Passed
api_v4_projects_merge_requests_merge_request_discussions | 200/s | 113.12/s (>80.00/s)  | 2926.15ms    | 100.00% (>95%)  | Passed
api_v4_projects_project                                  | 200/s | 188.73/s (>160.00/s) | 170.15ms     | 100.00% (>95%)  | Passed
api_v4_projects_project_pipelines                        | 200/s | 193.07/s (>160.00/s) | 102.53ms     | 100.00% (>95%)  | Passed
api_v4_projects_project_search_blobs                     | 200/s | 189.13/s (>80.00/s)  | 172.40ms     | 100.00% (>95%)  | Passed
api_v4_projects_repository_branches_branch               | 200/s | 190.7/s (>80.00/s)   | 131.90ms     | 100.00% (>95%)  | Passed
api_v4_projects_repository_commits                       | 200/s | 194.45/s (>160.00/s) | 84.48ms      | 100.00% (>95%)  | Passed
api_v4_projects_repository_commits_sha                   | 200/s | 194.18/s (>160.00/s) | 82.63ms      | 100.00% (>95%)  | Passed
api_v4_projects_repository_commits_sha_diff              | 200/s | 194.55/s (>160.00/s) | 80.40ms      | 100.00% (>95%)  | Passed
api_v4_projects_repository_commits_sha_signature         | 200/s | 194.52/s (>160.00/s) | 76.67ms      | 100.00% (>95%)  | Passed
api_v4_projects_repository_files_file                    | 200/s | 193.03/s (>160.00/s) | 111.79ms     | 100.00% (>95%)  | Passed
api_v4_projects_repository_files_file_raw                | 200/s | 191.33/s (>160.00/s) | 113.36ms     | 100.00% (>95%)  | Passed
api_v4_projects_repository_tree                          | 200/s | 194.25/s (>160.00/s) | 83.88ms      | 100.00% (>95%)  | Passed
api_v4_user                                              | 200/s | 196.02/s (>160.00/s) | 42.55ms      | 100.00% (>95%)  | Passed
git_ls_remote                                            | 200/s | 19.95/s (>16.00/s)   | 82.52ms      | 100.00% (>95%)  | Passed
git_pull                                                 | 20/s  | 19.48/s (>16.00/s)   | 84.83ms      | 100.00% (>95%)  | Passed
web_projects_blob_controller_show_html                   | 200/s | 183.35/s (>160.00/s) | 594.83ms     | 100.00% (>95%)  | Passed
```

* `NAME` - The name of the test run. Matches the filename of the test as found in the [`tests`](../k6/tests) folder
* `RPS` - The RPS target used during the test.
* `RPS RESULT` - The average Requests per Second the test was able to achieve throughout it's run along with it's passing threshold.
* `RESPONSE P95` - The 95th [percentile](https://en.wikipedia.org/wiki/Percentile_rank) of the response times seen by the test.
* `REQUEST RESULTS` - The percentage of requests made by the test that were successful (HTTP Code 200 / 201 returned) along with it's passing threshold.
* `RESULT` - The final result of the test.

As described above there are two thresholds that determine if the test has passed or not:

* RPS achieved by the test is above it's target threshold. The threshold is typically the target RPS (with a 20% buffer to account for network or other quirks) by default but tests can have their own different thresholds set depending on the area they are testing. Refer to each test to confirm thresholds
* That more than 95% of all requests made were successful (HTTP Code 200 / 201 returned)

More information on the results output from `k6` can be found over on it's documentation - [Results output](https://docs.k6.io/docs/results-output).

### Evaluating Failures

If any of the tests report RPS threshold failures these should be evaluated accordingly in line with the following:

* If any of the tests failed but only by a small amount (e.g. within 10% of the threshold) this is likely due to environmental or network conditions such as latency. As such, these can typically can be ignored if multiple sets of test runs report the same level of failures consistently. If seeking confidence the tests can be run again with a slightly lower RPS threshold modifier to confirm.
* If the failures are substantial (e.g. over 50% of the threshold) this would suggest an environment or product issue and further investigation may be required and should be escalated through the [appropriate channels](https://about.gitlab.com/support/) (e.g. A support ticket or an issue raised against the main GitLab project).

If any of the tests report more than 5% of failed requests outright this should be treated the same as a substantial RPS failure above and escalated through similar channels. A common example of this kind of failure is multiple http 500 code errors being thrown by areas that are completely unable to handle the expected throughput and subsequently failing completely.

### Comparing Results

We post our own results over on this [project's wiki](https://gitlab.com/gitlab-org/quality/performance/wikis/home) for transparency as well as allowing users to compare. 

Currently, you'll find the following results on our Wiki:
* [Latest Results](https://gitlab.com/gitlab-org/quality/performance/wikis/Benchmarks/Latest) - Our automated CI pipelines run multiple times each week and will post their result summaries to the wiki here each time.
* [GitLab Versions](https://gitlab.com/gitlab-org/quality/performance/wikis/Benchmarks/GitLab-Versions) - A collection of performance test results done against several select release versions of GitLab.
